{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import helpers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data set\n",
    "x_train, x_test, y_train, train_ids, test_ids = helpers.load_csv_data(data_path='data/dataset')\n",
    "print('train dataset dimensions: ', x_train.shape)\n",
    "print('train response dimensions: ', y_train.shape)\n",
    "print('test dataset dimensions', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the header\n",
    "with open('data/dataset/x_train.csv') as f:\n",
    "    first_line = f.readline().strip('\\n')\n",
    "f.close()\n",
    "\n",
    "header = first_line.split(',')\n",
    "header.remove('Id')\n",
    "# features = 'GENHLTH, PHYSHLTH, MENTHLTH, HLTHPLN1, PERSDOC2, MEDCOST, CHECKUP1, \n",
    "#              BPHIGH4, BLOODCHO, CHOLCHK, CVDSTRK3, ASTHMA3, CHCSCNCR, CHCOCNCR, CHCCOPD1, HAVARTH3, ADDEPEV2, CHCKIDNY, DIABETE3, SEX, MARITAL, EDUCA, RENTHOM1, VETERAN3, EMPLOY1, CHILDREN, INCOME2, INTERNET, PREGNANT, QLACTLM2, USEEQUIP, BLIND, DECIDE, DIFFWALK, DIFFDRES, DIFFALON, EXERANY2, SEATBELT, FLUSHOT6, PNEUVAC3, HIVTST6, RACE, _AGE80, HTM4, WTKG3, _BMI5, _RFBMI5, _SMOKER3, DROCDY3, DRNKWEK, _RFDRHV5, FTJUDA1, FRUTDA1_, BEANDAY_, GRENDAY_, ORNGDAY_, VEGEDA1_, FRT16, _VEG23, _FRUITEX, _VEGETEX, MAXVO2, FC60_, STRFREQ_, _PAINDX1, _PA30021, _PASTRNG'\n",
    "# features = features.split(', ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check each feauture and corresponding column indx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 _STATE\n",
      "1 FMONTH\n",
      "2 IDATE\n",
      "3 IMONTH\n",
      "4 IDAY\n",
      "5 IYEAR\n",
      "6 DISPCODE\n",
      "7 SEQNO\n",
      "8 _PSU\n",
      "9 CTELENUM\n",
      "10 PVTRESD1\n",
      "11 COLGHOUS\n",
      "12 STATERES\n",
      "13 CELLFON3\n",
      "14 LADULT\n",
      "15 NUMADULT\n",
      "16 NUMMEN\n",
      "17 NUMWOMEN\n",
      "18 CTELNUM1\n",
      "19 CELLFON2\n",
      "20 CADULT\n",
      "21 PVTRESD2\n",
      "22 CCLGHOUS\n",
      "23 CSTATE\n",
      "24 LANDLINE\n",
      "25 HHADULT\n",
      "26 GENHLTH\n",
      "27 PHYSHLTH\n",
      "28 MENTHLTH\n",
      "29 POORHLTH\n",
      "30 HLTHPLN1\n",
      "31 PERSDOC2\n",
      "32 MEDCOST\n",
      "33 CHECKUP1\n",
      "34 BPHIGH4\n",
      "35 BPMEDS\n",
      "36 BLOODCHO\n",
      "37 CHOLCHK\n",
      "38 TOLDHI2\n",
      "39 CVDSTRK3\n",
      "40 ASTHMA3\n",
      "41 ASTHNOW\n",
      "42 CHCSCNCR\n",
      "43 CHCOCNCR\n",
      "44 CHCCOPD1\n",
      "45 HAVARTH3\n",
      "46 ADDEPEV2\n",
      "47 CHCKIDNY\n",
      "48 DIABETE3\n",
      "49 DIABAGE2\n",
      "50 SEX\n",
      "51 MARITAL\n",
      "52 EDUCA\n",
      "53 RENTHOM1\n",
      "54 NUMHHOL2\n",
      "55 NUMPHON2\n",
      "56 CPDEMO1\n",
      "57 VETERAN3\n",
      "58 EMPLOY1\n",
      "59 CHILDREN\n",
      "60 INCOME2\n",
      "61 INTERNET\n",
      "62 WEIGHT2\n",
      "63 HEIGHT3\n",
      "64 PREGNANT\n",
      "65 QLACTLM2\n",
      "66 USEEQUIP\n",
      "67 BLIND\n",
      "68 DECIDE\n",
      "69 DIFFWALK\n",
      "70 DIFFDRES\n",
      "71 DIFFALON\n",
      "72 SMOKE100\n",
      "73 SMOKDAY2\n",
      "74 STOPSMK2\n",
      "75 LASTSMK2\n",
      "76 USENOW3\n",
      "77 ALCDAY5\n",
      "78 AVEDRNK2\n",
      "79 DRNK3GE5\n",
      "80 MAXDRNKS\n",
      "81 FRUITJU1\n",
      "82 FRUIT1\n",
      "83 FVBEANS\n",
      "84 FVGREEN\n",
      "85 FVORANG\n",
      "86 VEGETAB1\n",
      "87 EXERANY2\n",
      "88 EXRACT11\n",
      "89 EXEROFT1\n",
      "90 EXERHMM1\n",
      "91 EXRACT21\n",
      "92 EXEROFT2\n",
      "93 EXERHMM2\n",
      "94 STRENGTH\n",
      "95 LMTJOIN3\n",
      "96 ARTHDIS2\n",
      "97 ARTHSOCL\n",
      "98 JOINPAIN\n",
      "99 SEATBELT\n",
      "100 FLUSHOT6\n",
      "101 FLSHTMY2\n",
      "102 IMFVPLAC\n",
      "103 PNEUVAC3\n",
      "104 HIVTST6\n",
      "105 HIVTSTD3\n",
      "106 WHRTST10\n",
      "107 PDIABTST\n",
      "108 PREDIAB1\n",
      "109 INSULIN\n",
      "110 BLDSUGAR\n",
      "111 FEETCHK2\n",
      "112 DOCTDIAB\n",
      "113 CHKHEMO3\n",
      "114 FEETCHK\n",
      "115 EYEEXAM\n",
      "116 DIABEYE\n",
      "117 DIABEDU\n",
      "118 CAREGIV1\n",
      "119 CRGVREL1\n",
      "120 CRGVLNG1\n",
      "121 CRGVHRS1\n",
      "122 CRGVPRB1\n",
      "123 CRGVPERS\n",
      "124 CRGVHOUS\n",
      "125 CRGVMST2\n",
      "126 CRGVEXPT\n",
      "127 VIDFCLT2\n",
      "128 VIREDIF3\n",
      "129 VIPRFVS2\n",
      "130 VINOCRE2\n",
      "131 VIEYEXM2\n",
      "132 VIINSUR2\n",
      "133 VICTRCT4\n",
      "134 VIGLUMA2\n",
      "135 VIMACDG2\n",
      "136 CIMEMLOS\n",
      "137 CDHOUSE\n",
      "138 CDASSIST\n",
      "139 CDHELP\n",
      "140 CDSOCIAL\n",
      "141 CDDISCUS\n",
      "142 WTCHSALT\n",
      "143 LONGWTCH\n",
      "144 DRADVISE\n",
      "145 ASTHMAGE\n",
      "146 ASATTACK\n",
      "147 ASERVIST\n",
      "148 ASDRVIST\n",
      "149 ASRCHKUP\n",
      "150 ASACTLIM\n",
      "151 ASYMPTOM\n",
      "152 ASNOSLEP\n",
      "153 ASTHMED3\n",
      "154 ASINHALR\n",
      "155 HAREHAB1\n",
      "156 STREHAB1\n",
      "157 CVDASPRN\n",
      "158 ASPUNSAF\n",
      "159 RLIVPAIN\n",
      "160 RDUCHART\n",
      "161 RDUCSTRK\n",
      "162 ARTTODAY\n",
      "163 ARTHWGT\n",
      "164 ARTHEXER\n",
      "165 ARTHEDU\n",
      "166 TETANUS\n",
      "167 HPVADVC2\n",
      "168 HPVADSHT\n",
      "169 SHINGLE2\n",
      "170 HADMAM\n",
      "171 HOWLONG\n",
      "172 HADPAP2\n",
      "173 LASTPAP2\n",
      "174 HPVTEST\n",
      "175 HPLSTTST\n",
      "176 HADHYST2\n",
      "177 PROFEXAM\n",
      "178 LENGEXAM\n",
      "179 BLDSTOOL\n",
      "180 LSTBLDS3\n",
      "181 HADSIGM3\n",
      "182 HADSGCO1\n",
      "183 LASTSIG3\n",
      "184 PCPSAAD2\n",
      "185 PCPSADI1\n",
      "186 PCPSARE1\n",
      "187 PSATEST1\n",
      "188 PSATIME\n",
      "189 PCPSARS1\n",
      "190 PCPSADE1\n",
      "191 PCDMDECN\n",
      "192 SCNTMNY1\n",
      "193 SCNTMEL1\n",
      "194 SCNTPAID\n",
      "195 SCNTWRK1\n",
      "196 SCNTLPAD\n",
      "197 SCNTLWK1\n",
      "198 SXORIENT\n",
      "199 TRNSGNDR\n",
      "200 RCSGENDR\n",
      "201 RCSRLTN2\n",
      "202 CASTHDX2\n",
      "203 CASTHNO2\n",
      "204 EMTSUPRT\n",
      "205 LSATISFY\n",
      "206 ADPLEASR\n",
      "207 ADDOWN\n",
      "208 ADSLEEP\n",
      "209 ADENERGY\n",
      "210 ADEAT1\n",
      "211 ADFAIL\n",
      "212 ADTHINK\n",
      "213 ADMOVE\n",
      "214 MISTMNT\n",
      "215 ADANXEV\n",
      "216 QSTVER\n",
      "217 QSTLANG\n",
      "218 MSCODE\n",
      "219 _STSTR\n",
      "220 _STRWT\n",
      "221 _RAWRAKE\n",
      "222 _WT2RAKE\n",
      "223 _CHISPNC\n",
      "224 _CRACE1\n",
      "225 _CPRACE\n",
      "226 _CLLCPWT\n",
      "227 _DUALUSE\n",
      "228 _DUALCOR\n",
      "229 _LLCPWT\n",
      "230 _RFHLTH\n",
      "231 _HCVU651\n",
      "232 _RFHYPE5\n",
      "233 _CHOLCHK\n",
      "234 _RFCHOL\n",
      "235 _LTASTH1\n",
      "236 _CASTHM1\n",
      "237 _ASTHMS1\n",
      "238 _DRDXAR1\n",
      "239 _PRACE1\n",
      "240 _MRACE1\n",
      "241 _HISPANC\n",
      "242 _RACE\n",
      "243 _RACEG21\n",
      "244 _RACEGR3\n",
      "245 _RACE_G1\n",
      "246 _AGEG5YR\n",
      "247 _AGE65YR\n",
      "248 _AGE80\n",
      "249 _AGE_G\n",
      "250 HTIN4\n",
      "251 HTM4\n",
      "252 WTKG3\n",
      "253 _BMI5\n",
      "254 _BMI5CAT\n",
      "255 _RFBMI5\n",
      "256 _CHLDCNT\n",
      "257 _EDUCAG\n",
      "258 _INCOMG\n",
      "259 _SMOKER3\n",
      "260 _RFSMOK3\n",
      "261 DRNKANY5\n",
      "262 DROCDY3_\n",
      "263 _RFBING5\n",
      "264 _DRNKWEK\n",
      "265 _RFDRHV5\n",
      "266 FTJUDA1_\n",
      "267 FRUTDA1_\n",
      "268 BEANDAY_\n",
      "269 GRENDAY_\n",
      "270 ORNGDAY_\n",
      "271 VEGEDA1_\n",
      "272 _MISFRTN\n",
      "273 _MISVEGN\n",
      "274 _FRTRESP\n",
      "275 _VEGRESP\n",
      "276 _FRUTSUM\n",
      "277 _VEGESUM\n",
      "278 _FRTLT1\n",
      "279 _VEGLT1\n",
      "280 _FRT16\n",
      "281 _VEG23\n",
      "282 _FRUITEX\n",
      "283 _VEGETEX\n",
      "284 _TOTINDA\n",
      "285 METVL11_\n",
      "286 METVL21_\n",
      "287 MAXVO2_\n",
      "288 FC60_\n",
      "289 ACTIN11_\n",
      "290 ACTIN21_\n",
      "291 PADUR1_\n",
      "292 PADUR2_\n",
      "293 PAFREQ1_\n",
      "294 PAFREQ2_\n",
      "295 _MINAC11\n",
      "296 _MINAC21\n",
      "297 STRFREQ_\n",
      "298 PAMISS1_\n",
      "299 PAMIN11_\n",
      "300 PAMIN21_\n",
      "301 PA1MIN_\n",
      "302 PAVIG11_\n",
      "303 PAVIG21_\n",
      "304 PA1VIGM_\n",
      "305 _PACAT1\n",
      "306 _PAINDX1\n",
      "307 _PA150R2\n",
      "308 _PA300R2\n",
      "309 _PA30021\n",
      "310 _PASTRNG\n",
      "311 _PAREC1\n",
      "312 _PASTAE1\n",
      "313 _LMTACT1\n",
      "314 _LMTWRK1\n",
      "315 _LMTSCL1\n",
      "316 _RFSEAT2\n",
      "317 _RFSEAT3\n",
      "318 _FLSHOT6\n",
      "319 _PNEUMO2\n",
      "320 _AIDTST3\n"
     ]
    }
   ],
   "source": [
    "# check for each feauture the corresponding column index\n",
    "for i in range(len(header)):\n",
    "    print(i, header[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = x_train.shape[0]\n",
    "D = 65 # Number of features after feauture selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking only columns of interest from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aux matrix to store the data cleaned\n",
    "X = np.zeros((N,D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace(vec, src, dst=[np.nan], decrease=True):\n",
    "    '''\n",
    "    Replace the values in the vector vec that are in src by the values in dst.\n",
    "    '''\n",
    "    if len(dst) != 1:\n",
    "        for i in range(len(src)):\n",
    "            vec[vec == src[i]] = dst[i]\n",
    "    else:\n",
    "        for e in src:\n",
    "            vec[vec == e] = dst[0]\n",
    "    if decrease:\n",
    "        vec = vec - 1     \n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:,0] = replace(x_train[:,header.index('GENHLTH')], [7,9])\n",
    "X[:,1] = replace(x_train[:,header.index('PHYSHLTH')], [88,77,99], [0,np.nan,np.nan], False)\n",
    "X[:,2] = replace(x_train[:,header.index('MENTHLTH')], [88,77,99], [0,np.nan,np.nan], False)  # checked\n",
    "X[:,3] = replace(x_train[:,header.index('HLTHPLN1')], [7,9])\n",
    "X[:,4] = replace(x_train[:,header.index('PERSDOC2')], [3,7,9], [0,np.nan,np.nan], False)\n",
    "X[:,5] = replace(x_train[:,header.index('MEDCOST')], [7,9])\n",
    "X[:,6] = replace(x_train[:,header.index('CHECKUP1')], [7,8,9], [np.nan,5,np.nan])\n",
    "X[:,7] = replace(x_train[:,header.index('BPHIGH4')], [1,2,3,4,7,9], [2,2,0,1,np.nan,np.nan], False)\n",
    "X[:,8] = replace(x_train[:,header.index('BPMEDS')], [7,9]) #############\n",
    "X[:,9] = replace(x_train[:,header.index('BLOODCHO')], [7,9])\n",
    "X[:,10] = replace(x_train[:,header.index('CHOLCHK')], [7,9])\n",
    "X[:,11] = replace(x_train[:,header.index('CVDSTRK3')], [7,9])\n",
    "X[:,12] = replace(x_train[:,header.index('ASTHMA3')], [7,9])\n",
    "X[:,13] = replace(x_train[:,header.index('CHCSCNCR')], [7,9])\n",
    "X[:,14] = replace(x_train[:,header.index('CHCOCNCR')], [7,9])\n",
    "X[:,15] = replace(x_train[:,header.index('CHCCOPD1')], [7,9])\n",
    "X[:,16] = replace(x_train[:,header.index('ADDEPEV2')], [7,9])\n",
    "X[:,17] = replace(x_train[:,header.index('CHCKIDNY')], [7,9])\n",
    "X[:,18] = replace(x_train[:,header.index('DIABETE3')], [1,2,3,4,7,9], [2,2,0,1,np.nan,np.nan], False)\n",
    "X[:,19] = replace(x_train[:,header.index('SEX')], [1,2], [0,1], False)\n",
    "X[:,20] = replace(x_train[:,header.index('MARITAL')], [1,2,3,4,5,6,9], [5,2,1,3,0,4,np.nan], False)\n",
    "X[:,21] = replace(x_train[:,header.index('EDUCA')], [1,2,3,4,5,6,9], [0,1,2,3,4,5,np.nan], False)\n",
    "X[:,22] = replace(x_train[:,header.index('RENTHOM1')], [3,7,9])\n",
    "X[:,23] = replace(x_train[:,header.index('VETERAN3')], [7,9])\n",
    "X[:,24] = replace(x_train[:,header.index('EMPLOY1')], [9], [np.nan])\n",
    "X[:,25] = replace(x_train[:,header.index('CHILDREN')], [88, 99], [0,np.nan], False)\n",
    "X[:,26] = replace(x_train[:,header.index('INCOME2')], [77, 99])\n",
    "X[:,27] = replace(x_train[:,header.index('INTERNET')], [7,9], [np.nan,np.nan])\n",
    "X[:,28] = replace(x_train[:,header.index('PREGNANT')], [7,9], [np.nan,np.nan])\n",
    "X[:,29] = replace(x_train[:,header.index('QLACTLM2')], [7,9], [np.nan,np.nan])\n",
    "X[:,30] = replace(x_train[:,header.index('USEEQUIP')], [7,9], [np.nan,np.nan])\n",
    "X[:,31] = replace(x_train[:,header.index('BLIND')], [7,9], [np.nan,np.nan])\n",
    "X[:,32] = replace(x_train[:,header.index('DECIDE')], [7,9], [np.nan,np.nan])\n",
    "X[:,33] = replace(x_train[:,header.index('DIFFWALK')], [7,9], [np.nan,np.nan])\n",
    "X[:,34] = replace(x_train[:,header.index('DIFFDRES')], [7,9], [np.nan,np.nan])\n",
    "X[:,35] = replace(x_train[:,header.index('DIFFALON')], [7,9], [np.nan,np.nan])\n",
    "X[:,36] = replace(x_train[:,header.index('EXERANY2')], [7,9], [np.nan,np.nan])\n",
    "X[:,37] = replace(x_train[:,header.index('SEATBELT')], [7,9], [np.nan,np.nan])\n",
    "X[:,38] = replace(x_train[:,header.index('FLUSHOT6')], [7,9], [np.nan,np.nan])\n",
    "X[:,39] = replace(x_train[:,header.index('PNEUVAC3')], [7,9], [np.nan,np.nan])\n",
    "X[:,40] = replace(x_train[:,header.index('HIVTST6')], [7,9], [np.nan,np.nan])\n",
    "X[:,41] = x_train[:,header.index('_DRDXAR1')] ##########\n",
    "X[:,42] = replace(x_train[:,header.index('_RACE')], [9])\n",
    "X[:,43] = x_train[:,header.index('_AGE80')]\n",
    "X[:,44] = x_train[:,header.index('HTM4')]\n",
    "X[:,45] = replace(x_train[:,header.index('WTKG3')], [99999])\n",
    "X[:,46] = x_train[:,header.index('_BMI5')]\n",
    "X[:,47] = replace(x_train[:,header.index('_SMOKER3')], [9], [np.nan])\n",
    "X[:,48] = replace(x_train[:,header.index('DROCDY3_')], [900], decrease=False) # checked\n",
    "X[:,49] = replace(x_train[:,header.index('_DRNKWEK')], [99900], decrease=False)  # checked\n",
    "X[:,50] = replace(x_train[:,header.index('_RFDRHV5')], [9], [np.nan])\n",
    "X[:,51] = x_train[:,header.index('FTJUDA1_')]\n",
    "X[:,52] = x_train[:,header.index('FRUTDA1_')]\n",
    "X[:,53] = x_train[:,header.index('BEANDAY_')]\n",
    "X[:,54] = x_train[:,header.index('GRENDAY_')]\n",
    "X[:,55] = x_train[:,header.index('ORNGDAY_')]\n",
    "X[:,56] = x_train[:,header.index('VEGEDA1_')]\n",
    "X[:,57] = replace(x_train[:,header.index('MAXVO2_')], [99900], [np.nan])\n",
    "X[:,58] = replace(x_train[:,header.index('FC60_')], [99900], [np.nan], False) # checked\n",
    "X[:,59] = replace(x_train[:,header.index('STRFREQ_')], [99000], decrease=False) # checked\n",
    "X[:,60] = replace(x_train[:,header.index('_PAINDX1')], [9], [np.nan])\n",
    "X[:,61] = replace(x_train[:,header.index('_PA30021')], [9], [np.nan])\n",
    "X[:,62] = replace(x_train[:,header.index('_PASTRNG')], [9], [np.nan])\n",
    "\n",
    "\n",
    "X[:,63] = x_train[:,header.index('_FRT16')] # to be discarded after data cleaning\n",
    "X[:,64] = x_train[:,header.index('_VEG23')] # to be discarded after data cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling some columns with out of range values\n",
    "# Fruit \n",
    "X[:, 51][X[:, 63]== 0 ]= np.nan # FTJUDA1, reference: FRT16\n",
    "X[:, 52][X[:, 63]== 0] = np.nan # FRUTDA1, reference: FRT16\n",
    "\n",
    "# Vegetables \n",
    "X[:, 53][X[:,64] == 0 ]= np.nan # BEANDAY, reference: _VEG23\n",
    "X[:, 54][X[:,64] == 0] = np.nan # GRENDAY, reference: _VEG23\n",
    "X[:, 55][X[:,64] == 0] = np.nan # ORNGDAY, reference: _VEG23\n",
    "X[:, 56][X[:,64] == 0] = np.nan# VEGEDA1, reference: _VEG23\n",
    "\n",
    "\n",
    "# remove column 63 and 64\n",
    "X = np.delete(X, [63,64], axis=1)\n",
    "# check in which columns we have negative values\n",
    "for i in range(D-2):\n",
    "    if np.any(X[:,i] < 0):\n",
    "        print(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Replacing nans with values from similar rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def standardize(x):\n",
    "    '''\n",
    "    Standardize the data set x.\n",
    "    '''\n",
    "    means = np.nanmean(x, axis=0)\n",
    "    stds = np.nanstd(x, axis=0) \n",
    "    stds[stds == 0] = 1  \n",
    "    std_data = (x - means) / stds \n",
    "    return std_data\n",
    "    \n",
    "def get_nan_indeces(row):\n",
    "    '''\n",
    "    Get the indeces of the nan values in a specific row.\n",
    "    '''\n",
    "    return np.argwhere(np.isnan(row))\n",
    "    \n",
    "def get_similar_rows(row_index, X, n=1000):\n",
    "    '''\n",
    "    Get the n most similar rows to the row with index row_index in the matrix X.\n",
    "    RETURNS THE INDECES OF THE ROWS sorted\n",
    "    '''\n",
    "    nans = get_nan_indeces(X[row_index,:])\n",
    "    # remove rows with nan values in nans\n",
    "    \n",
    "    temp = np.delete(X, nans, axis=1)\n",
    "    norms = np.linalg.norm(temp, axis=1)\n",
    "    target = norms[row_index]\n",
    "    norms = np.delete(norms, row_index)\n",
    "    norms = np.abs(norms - target)\n",
    "    # indeces = np.argsort(norms)[:n]\n",
    "    indeces = np.argsort(norms)\n",
    "    # return X[indeces,:]\n",
    "    return indeces\n",
    "    \n",
    "def replace_value(similar_rows, col_index, median_indices, mean_indices):\n",
    "    '''\n",
    "    Replace the nan value in the column col_index of the row \n",
    "    with the mean of the values in the same column of the similar rows\n",
    "    '''\n",
    "    if col_index in median_indices:\n",
    "        return np.median(similar_rows[:,col_index])\n",
    "    elif col_index in mean_indices:\n",
    "        return np.mean(similar_rows[:,col_index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = standardize(X)\n",
    "S1 = np.copy(X)\n",
    "rows, cols = np.where(np.isnan(S))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the indices of the columns that will be replaced by the median ( for categorical data )\n",
    "median_indices = [0, 3, 4, 5, 6, 7, 8, 9, 10,  11,  12, 13, 14,  15, 16,  17, 18, 19,  20, 21, 22, \n",
    "                23,  24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, \n",
    "                43, 47, 50, 60, 61, 62]\n",
    "\n",
    "# defining the indices of the columns that will be replaced by the mean ( for continous data )\n",
    "mean_indices = [1, 2, 25, 44, 45, 46, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in set(rows):\n",
    "    # print(\"looking at row \", i)\n",
    "    similar_rows_indices = get_similar_rows(i, S)\n",
    "    # print(similar_rows_indices.shape)\n",
    "    for j in cols[rows == i]:\n",
    "        # print(\"looking at column \", j)\n",
    "        # find similar rows in the matrix only taking th efirst 1000 that do not have nan in the column j\n",
    "        non_nan_mask = ~np.isnan(S[similar_rows_indices, j])\n",
    "        # Apply the mask to get valid row indices (rows without NaN in column j)\n",
    "        valid_rows = similar_rows_indices[non_nan_mask]\n",
    "        # Select the top K rows\n",
    "        top_k_similar_idx = valid_rows[:1000]\n",
    "        top_k_similar_rows = S1[top_k_similar_idx]\n",
    "        # print(top_k_similar_rows)\n",
    "        S1[i, j] = replace_value(top_k_similar_rows, j, median_indices, mean_indices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the cleaned data set in new_data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the file in numpy format\n",
    "np.save('new_data/cleaned_data.npy', S1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
